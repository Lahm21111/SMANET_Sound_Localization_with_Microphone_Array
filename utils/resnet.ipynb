{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First load the data from .h5 file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: audio, Shape: (100, 2400, 4)\n",
      "Dataset: label, Shape: (100, 5)\n",
      "Dataset: stft, Shape: (100, 8, 168, 7)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "# Path to the H5 file\n",
    "h5_file_path = r\"C:\\Users\\grizi\\Desktop\\TUD\\year2\\thesis\\neural_network\\DoA_Net\\data\\stft.h5\"\n",
    "\n",
    "# Open the H5 file\n",
    "with h5py.File(h5_file_path, 'r') as h5file:\n",
    "    # Iterate through each dataset in the H5 file\n",
    "    for dataset_name in h5file:\n",
    "        # Get the dataset\n",
    "        dataset = h5file[dataset_name]\n",
    "        if dataset_name == 'audio':\n",
    "            audio_data = np.array(dataset)\n",
    "        elif dataset_name == 'label':\n",
    "            label_data = np.array(dataset)\n",
    "        elif dataset_name == 'stft':\n",
    "            stft_data = np.array(dataset)\n",
    "        \n",
    "        # Print the dataset name and its shape\n",
    "        print(f\"Dataset: {dataset_name}, Shape: {dataset.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn the label to a Gaussian Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.74878501e-43, 2.00500878e-37, 5.38018616e-32, 5.31109225e-27,\n",
       "       1.92874985e-22, 2.57675711e-18, 1.26641655e-14, 2.28973485e-11,\n",
       "       1.52299797e-08, 3.72665317e-06, 3.35462628e-04, 1.11089965e-02,\n",
       "       1.35335283e-01, 6.06530660e-01, 1.00000000e+00, 6.06530660e-01,\n",
       "       1.35335283e-01, 1.11089965e-02, 3.35462628e-04, 3.72665317e-06,\n",
       "       1.52299797e-08, 2.28973485e-11, 1.26641655e-14, 2.57675711e-18,\n",
       "       1.92874985e-22, 5.31109225e-27, 5.38018616e-32, 2.00500878e-37,\n",
       "       2.74878501e-43, 1.38634329e-49, 2.57220937e-56])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_gaussian(center, start, end, peak_value=1, sigma=1):\n",
    "\n",
    "    x = np.arange(start, end + 1)  # Generate the range from start to end\n",
    "    gaussian = np.exp(-0.5 * ((x - center) ** 2) / (sigma ** 2))  # Gaussian formula\n",
    "    gaussian = gaussian / gaussian.max() * peak_value  # Normalize to make the peak value equal to `peak_value`\n",
    "    return gaussian\n",
    "\n",
    "# Generate Gaussian distribution from 1 to 11 with peak at 6\n",
    "start, end, center = 1, 31, 15\n",
    "sigma = 1  # Standard deviation\n",
    "gaussian_distribution = generate_gaussian(center, start, end, peak_value=1, sigma=sigma)\n",
    "\n",
    "gaussian_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n",
      "(100, 360)\n"
     ]
    }
   ],
   "source": [
    "angle_label =  label_data[:,3]\n",
    "print(angle_label.shape)\n",
    "zero_matrix_train = np.zeros((len(angle_label),360))\n",
    "\n",
    "# Define the Gaussian distribution function\n",
    "def gaussian_labeling(label, num_classes=360):\n",
    "\n",
    "    zero_row = np.zeros((num_classes))\n",
    "    for i in range(31):\n",
    "        center = label + i - 15\n",
    "        if center < 0:\n",
    "            center = 360 + center\n",
    "        elif center > 359:\n",
    "            center = center - 360\n",
    "        zero_row[center] = gaussian_distribution[i]\n",
    "\n",
    "    return zero_row\n",
    "\n",
    "    \n",
    "\n",
    "# set the method for encoding the labels\n",
    "encode_method = \"gaussian\"\n",
    "\n",
    "# encode the labels as a gaussian distribution\n",
    "possibility_matrix_angle = zero_matrix_train\n",
    "\n",
    "for i in range(len(angle_label)):\n",
    "    ground_truth_angle = int(angle_label[i])  # Ground truth angle\n",
    "    possibility_matrix_angle[i,:] = gaussian_labeling(ground_truth_angle, 360)\n",
    "\n",
    "\n",
    "# possibility_matrix now contains the Gaussian-encoded labels\n",
    "print(possibility_matrix_angle.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([4, 1, 360])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=(3, 3), padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(channels)\n",
    "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=(3, 3), padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(channels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += residual  # Shortcut connection\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class DOA_Network(nn.Module):\n",
    "    def __init__(self, input_channels=8, time_steps=7, doa_bins=360):\n",
    "        super(DOA_Network, self).__init__()\n",
    "        \n",
    "        # 1x7 Convolution, stride (1,3), output channels 32\n",
    "        self.conv1 = nn.Conv2d(in_channels=input_channels, out_channels=32, kernel_size=(1, 7), stride=(1, 3))\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        # 1x5 Convolution, stride (1,2), output channels 128\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=128, kernel_size=(1, 5), stride=(1, 2))\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        # 5 Residual Blocks\n",
    "        self.res_blocks = nn.Sequential(*[ResidualBlock(128) for _ in range(5)])\n",
    "        \n",
    "        # 1x1 Convolution, output channels 360 (DOA bins)\n",
    "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=doa_bins, kernel_size=(1, 1))\n",
    "        self.bn3 = nn.BatchNorm2d(doa_bins)\n",
    "        \n",
    "        # 1x1 Convolution, output channels 500\n",
    "        self.conv4 = nn.Conv2d(in_channels=25, out_channels=500, kernel_size=(1, 1))\n",
    "        self.bn4 = nn.BatchNorm2d(500)\n",
    "        \n",
    "        # 7x5 Convolution, output channels 1 (Final Spatial Spectrum Output)\n",
    "        self.conv5 = nn.Conv2d(in_channels=500, out_channels=1, kernel_size=(7, 5), padding=(0, 2))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Initial convolutions\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        \n",
    "        # Residual blocks\n",
    "        x = self.res_blocks(x)\n",
    "        \n",
    "        # 1x1 Convolution to DOA bins\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        \n",
    "        # Swap axes (B, T, DOA, F) -> (B, T, F, DOA)\n",
    "        x = x.permute(0, 3, 2, 1) \n",
    "        \n",
    "        # 1x1 Convolution\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        \n",
    "        # Final 7x5 Convolution with Sigmoid activation\n",
    "        x = torch.sigmoid(self.conv5(x))\n",
    "        \n",
    "        # Remove channel dimension and return (B, T, DOA)\n",
    "        x = x.squeeze(1)\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Define input dimensions (Batch, Channels, Time, Frequency)\n",
    "    batch_size = 4\n",
    "    input_tensor = torch.randn(batch_size, 8, 7, 168)  # (B, C, T, F)\n",
    "    \n",
    "    model = DOA_Network()\n",
    "    output = model(input_tensor)\n",
    "    print(\"Output shape:\", output.shape)  # Expected: (B, T, 360)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets start a training phase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 7, 168])\n",
      "torch.Size([1, 360])\n",
      "Epoch [1/100], Loss: 0.2060\n",
      "Epoch [2/100], Loss: 0.0049\n",
      "Epoch [3/100], Loss: 0.0049\n",
      "Epoch [4/100], Loss: 0.0049\n",
      "Epoch [5/100], Loss: 0.0049\n",
      "Epoch [6/100], Loss: 0.0049\n",
      "Epoch [7/100], Loss: 0.0049\n",
      "Epoch [8/100], Loss: 0.0049\n",
      "Epoch [9/100], Loss: 0.0049\n",
      "Epoch [10/100], Loss: 0.0049\n",
      "Epoch [11/100], Loss: 0.0049\n",
      "Epoch [12/100], Loss: 0.0049\n",
      "Epoch [13/100], Loss: 0.0049\n",
      "Epoch [14/100], Loss: 0.0049\n",
      "Epoch [15/100], Loss: 0.0049\n",
      "Epoch [16/100], Loss: 0.0049\n",
      "Epoch [17/100], Loss: 0.0049\n",
      "Epoch [18/100], Loss: 0.0049\n",
      "Epoch [19/100], Loss: 0.0049\n",
      "Epoch [20/100], Loss: 0.0049\n",
      "Epoch [21/100], Loss: 0.0049\n",
      "Epoch [22/100], Loss: 0.0049\n",
      "Epoch [23/100], Loss: 0.0049\n",
      "Epoch [24/100], Loss: 0.0049\n",
      "Epoch [25/100], Loss: 0.0049\n",
      "Epoch [26/100], Loss: 0.0049\n",
      "Epoch [27/100], Loss: 0.0049\n",
      "Epoch [28/100], Loss: 0.0049\n",
      "Epoch [29/100], Loss: 0.0049\n",
      "Epoch [30/100], Loss: 0.0049\n",
      "Epoch [31/100], Loss: 0.0049\n",
      "Epoch [32/100], Loss: 0.0049\n",
      "Epoch [33/100], Loss: 0.0049\n",
      "Epoch [34/100], Loss: 0.0049\n",
      "Epoch [35/100], Loss: 0.0049\n",
      "Epoch [36/100], Loss: 0.0049\n",
      "Epoch [37/100], Loss: 0.0049\n",
      "Epoch [38/100], Loss: 0.0049\n",
      "Epoch [39/100], Loss: 0.0049\n",
      "Epoch [40/100], Loss: 0.0049\n",
      "Epoch [41/100], Loss: 0.0049\n",
      "Epoch [42/100], Loss: 0.0049\n",
      "Epoch [43/100], Loss: 0.0049\n",
      "Epoch [44/100], Loss: 0.0049\n",
      "Epoch [45/100], Loss: 0.0049\n",
      "Epoch [46/100], Loss: 0.0049\n",
      "Epoch [47/100], Loss: 0.0049\n",
      "Epoch [48/100], Loss: 0.0049\n",
      "Epoch [49/100], Loss: 0.0049\n",
      "Epoch [50/100], Loss: 0.0049\n",
      "Epoch [51/100], Loss: 0.0049\n",
      "Epoch [52/100], Loss: 0.0049\n",
      "Epoch [53/100], Loss: 0.0049\n",
      "Epoch [54/100], Loss: 0.0049\n",
      "Epoch [55/100], Loss: 0.0049\n",
      "Epoch [56/100], Loss: 0.0049\n",
      "Epoch [57/100], Loss: 0.0049\n",
      "Epoch [58/100], Loss: 0.0049\n",
      "Epoch [59/100], Loss: 0.0049\n",
      "Epoch [60/100], Loss: 0.0049\n",
      "Epoch [61/100], Loss: 0.0049\n",
      "Epoch [62/100], Loss: 0.0049\n",
      "Epoch [63/100], Loss: 0.0049\n",
      "Epoch [64/100], Loss: 0.0049\n",
      "Epoch [65/100], Loss: 0.0049\n",
      "Epoch [66/100], Loss: 0.0049\n",
      "Epoch [67/100], Loss: 0.0049\n",
      "Epoch [68/100], Loss: 0.0049\n",
      "Epoch [69/100], Loss: 0.0049\n",
      "Epoch [70/100], Loss: 0.0049\n",
      "Epoch [71/100], Loss: 0.0049\n",
      "Epoch [72/100], Loss: 0.0049\n",
      "Epoch [73/100], Loss: 0.0049\n",
      "Epoch [74/100], Loss: 0.0049\n",
      "Epoch [75/100], Loss: 0.0049\n",
      "Epoch [76/100], Loss: 0.0049\n",
      "Epoch [77/100], Loss: 0.0049\n",
      "Epoch [78/100], Loss: 0.0049\n",
      "Epoch [79/100], Loss: 0.0049\n",
      "Epoch [80/100], Loss: 0.0049\n",
      "Epoch [81/100], Loss: 0.0049\n",
      "Epoch [82/100], Loss: 0.0049\n",
      "Epoch [83/100], Loss: 0.0049\n",
      "Epoch [84/100], Loss: 0.0049\n",
      "Epoch [85/100], Loss: 0.0049\n",
      "Epoch [86/100], Loss: 0.0049\n",
      "Epoch [87/100], Loss: 0.0049\n",
      "Epoch [88/100], Loss: 0.0049\n",
      "Epoch [89/100], Loss: 0.0049\n",
      "Epoch [90/100], Loss: 0.0049\n",
      "Epoch [91/100], Loss: 0.0049\n",
      "Epoch [92/100], Loss: 0.0049\n",
      "Epoch [93/100], Loss: 0.0049\n",
      "Epoch [94/100], Loss: 0.0049\n",
      "Epoch [95/100], Loss: 0.0049\n",
      "Epoch [96/100], Loss: 0.0049\n",
      "Epoch [97/100], Loss: 0.0049\n",
      "Epoch [98/100], Loss: 0.0049\n",
      "Epoch [99/100], Loss: 0.0049\n",
      "Epoch [100/100], Loss: 0.0049\n",
      "Prediction shape: torch.Size([1, 1, 360])\n",
      "Maximum value index: 0\n",
      "Maximum value index: 194\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "    \n",
    "# Training function\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "# Prediction function\n",
    "def predict(model, input_tensor, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input_tensor = input_tensor.to(device)\n",
    "        output = model(input_tensor)\n",
    "    return output.cpu()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Define input dimensions (Batch, Channels, Time, Frequency)\n",
    "    batch_size = 1\n",
    "    input_tensor = torch.from_numpy(stft_data).float()\n",
    "    input_tensor = input_tensor.permute(0, 1, 3, 2)  # Swap axes (B, F, T, C)\n",
    "    print(input_tensor.shape)\n",
    "    target_tensor = torch.from_numpy(possibility_matrix_angle).float()\n",
    "    print(target_tensor.shape)\n",
    "    \n",
    "    # Create dataset and dataloader\n",
    "    dataset = CustomDataset(input_tensor, target_tensor)\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Initialize model, loss function, and optimizer\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = DOA_Network().to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Train the model\n",
    "    train_model(model, train_loader, criterion, optimizer, num_epochs=100)\n",
    "\n",
    "    # Prediction example\n",
    "    test_input = input_tensor\n",
    "    prediction = predict(model, test_input, device)\n",
    "    print(\"Prediction shape:\", prediction.shape)\n",
    "\n",
    "    max_index = torch.argmax(prediction[0], dim=1).item()\n",
    "    print(f\"Maximum value index: {max_index}\")\n",
    "\n",
    "    max_index = torch.argmax(target_tensor, dim=1).item()\n",
    "    print(f\"Maximum value index: {max_index}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dt-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
