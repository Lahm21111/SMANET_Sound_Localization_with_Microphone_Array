{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Reader for Integration\n",
    "\n",
    "This Jupyter Notebook integrates data by extracting audio from `.wav` files and localization information from `.csv` files. The processed data is saved into an `.h5` file, preparing it for the training phase.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Check the structure of the auido file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "import numpy as np\n",
    "\n",
    "def read_wav_file(file_path):\n",
    "    # Open WAV file\n",
    "    with wave.open(file_path, 'rb') as wav_file:\n",
    "        # Get WAV file parameters\n",
    "        n_channels = wav_file.getnchannels()  # Number of channels\n",
    "        sample_width = wav_file.getsampwidth()  # Bytes per sample\n",
    "        frame_rate = wav_file.getframerate()  # Sampling rate\n",
    "        n_frames = wav_file.getnframes()  # Total number of frames\n",
    "        audio_format = wav_file.getcomptype()  # Compression type (usually 'NONE' for no compression)\n",
    "\n",
    "        # Read audio data\n",
    "        raw_data = wav_file.readframes(n_frames)  # Read all frames\n",
    "        audio_data = np.frombuffer(raw_data, dtype=np.int16)  # Convert to NumPy array\n",
    "        \n",
    "        # If multi-channel, split audio data into separate channels\n",
    "        if n_channels > 1:\n",
    "            audio_data = np.reshape(audio_data, (-1, n_channels))\n",
    "        \n",
    "        return audio_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\grizi\\\\Desktop\\\\TUD\\\\year2\\\\thesis\\\\neural_network\\\\DoA_Net\\\\data\\\\mic_dev\\\\mic_dev\\\\fold6_room1_mix087_ov2.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;66;03m# Replace with your WAV file path\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     wav_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mgrizi\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mTUD\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124myear2\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mthesis\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mneural_network\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDoA_Net\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmic_dev\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmic_dev\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mfold6_room1_mix087_ov2.wav\u001b[39m\u001b[38;5;124m'\u001b[39m  \n\u001b[1;32m---> 27\u001b[0m     audio_data \u001b[38;5;241m=\u001b[39m \u001b[43mread_wav_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwav_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(audio_data\u001b[38;5;241m.\u001b[39mshape)\n",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m, in \u001b[0;36mread_wav_file\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_wav_file\u001b[39m(file_path):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Open WAV file\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mwave\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m wav_file:\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;66;03m# Get WAV file parameters\u001b[39;00m\n\u001b[0;32m      8\u001b[0m         n_channels \u001b[38;5;241m=\u001b[39m wav_file\u001b[38;5;241m.\u001b[39mgetnchannels()  \u001b[38;5;66;03m# Number of channels\u001b[39;00m\n\u001b[0;32m      9\u001b[0m         sample_width \u001b[38;5;241m=\u001b[39m wav_file\u001b[38;5;241m.\u001b[39mgetsampwidth()  \u001b[38;5;66;03m# Bytes per sample\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\grizi\\anaconda3\\envs\\seld\\lib\\wave.py:509\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(f, mode)\u001b[0m\n\u001b[0;32m    507\u001b[0m         mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mWave_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Wave_write(f)\n",
      "File \u001b[1;32mc:\\Users\\grizi\\anaconda3\\envs\\seld\\lib\\wave.py:159\u001b[0m, in \u001b[0;36mWave_read.__init__\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_i_opened_the_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 159\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_i_opened_the_file \u001b[38;5;241m=\u001b[39m f\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# else, assume it is an open file object already\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\grizi\\\\Desktop\\\\TUD\\\\year2\\\\thesis\\\\neural_network\\\\DoA_Net\\\\data\\\\mic_dev\\\\mic_dev\\\\fold6_room1_mix087_ov2.wav'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Replace with your WAV file path\n",
    "    wav_file_path = r'C:\\Users\\grizi\\Desktop\\TUD\\year2\\thesis\\neural_network\\DoA_Net\\data\\mic_dev\\mic_dev\\fold6_room1_mix087_ov2.wav'  \n",
    "    audio_data = read_wav_file(wav_file_path)\n",
    "    print(audio_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Check the structure of the csv file : read the data from the csv file and form the data as an array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\grizi\\\\Desktop\\\\TUD\\\\year2\\\\thesis\\\\neural_network\\\\DoA_Net\\\\data\\\\metadata_dev\\\\metadata_dev\\\\fold1_room1_mix001_ov1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m# Replace with your CSV file path\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     csv_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mgrizi\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mTUD\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124myear2\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mthesis\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mneural_network\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDoA_Net\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmetadata_dev\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmetadata_dev\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mfold1_room1_mix001_ov1.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 25\u001b[0m     header, data \u001b[38;5;241m=\u001b[39m \u001b[43mread_csv_file_to_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# Print the first few rows\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(data[:\u001b[38;5;241m5\u001b[39m])\n",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m, in \u001b[0;36mread_csv_file_to_numpy\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread_csv_file_to_numpy\u001b[39m(file_path):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Open the CSV file\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m csv_file:\n\u001b[0;32m      7\u001b[0m         csv_reader \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mreader(csv_file)\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;66;03m# Read the header\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\grizi\\anaconda3\\envs\\audio\\lib\\site-packages\\IPython\\core\\interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[1;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\grizi\\\\Desktop\\\\TUD\\\\year2\\\\thesis\\\\neural_network\\\\DoA_Net\\\\data\\\\metadata_dev\\\\metadata_dev\\\\fold1_room1_mix001_ov1.csv'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "def read_csv_file_to_numpy(file_path):\n",
    "    # Open the CSV file\n",
    "    with open(file_path, mode='r', newline='', encoding='utf-8') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file)\n",
    "        \n",
    "        # Read the header\n",
    "        header = next(csv_reader)\n",
    "        print(f\"Header: {header}\")\n",
    "        \n",
    "        # Read the rows and convert to NumPy array\n",
    "        rows = []\n",
    "        for row in csv_reader:\n",
    "            rows.append(row)\n",
    "        \n",
    "        data = np.array(rows)\n",
    "        print(f\"Data Shape: {data.shape}\")\n",
    "        return header, data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace with your CSV file path\n",
    "    csv_file_path = r'C:\\Users\\grizi\\Desktop\\TUD\\year2\\thesis\\neural_network\\DoA_Net\\data\\metadata_dev\\metadata_dev\\fold1_room1_mix001_ov1.csv'\n",
    "    header, data = read_csv_file_to_numpy(csv_file_path)\n",
    "    \n",
    "    # Print the first few rows\n",
    "    print(data[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take all the data with only one sound \n",
    "\n",
    "split the sound file first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 系统找不到指定的路径。: 'C:\\\\Users\\\\grizi\\\\Desktop\\\\TUD\\\\year2\\\\thesis\\\\neural_network\\\\DoA_Net\\\\data\\\\mic_dev\\\\mic_dev'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m test_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mgrizi\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mTUD\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124myear2\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mthesis\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mneural_network\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDoA_Net\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mov1_mic_dev\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Split files\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m \u001b[43msplit_ov1_files_into_folders\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_folder\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 11\u001b[0m, in \u001b[0;36msplit_ov1_files_into_folders\u001b[1;34m(src_folder, train_folder, val_folder, test_folder)\u001b[0m\n\u001b[0;32m      8\u001b[0m         os\u001b[38;5;241m.\u001b[39mmakedirs(folder)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Iterate over all files in the source folder\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_folder\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# Check if the file ends with '_ov1' and move to the corresponding folder\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_ov1.wav\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mstartswith((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold3\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold4\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold5\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold6\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 系统找不到指定的路径。: 'C:\\\\Users\\\\grizi\\\\Desktop\\\\TUD\\\\year2\\\\thesis\\\\neural_network\\\\DoA_Net\\\\data\\\\mic_dev\\\\mic_dev'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def split_ov1_files_into_folders(src_folder, train_folder, val_folder, test_folder):\n",
    "    # Create destination folders if they don't exist\n",
    "    for folder in [train_folder, val_folder, test_folder]:\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "    \n",
    "    # Iterate over all files in the source folder\n",
    "    for filename in os.listdir(src_folder):\n",
    "        # Check if the file ends with '_ov1' and move to the corresponding folder\n",
    "        if filename.endswith('_ov1.wav'):\n",
    "            if filename.startswith(('fold3', 'fold4', 'fold5', 'fold6')):\n",
    "                shutil.move(os.path.join(src_folder, filename), os.path.join(train_folder, filename))\n",
    "            elif filename.startswith('fold2'):\n",
    "                shutil.move(os.path.join(src_folder, filename), os.path.join(val_folder, filename))\n",
    "            elif filename.startswith('fold1'):\n",
    "                shutil.move(os.path.join(src_folder, filename), os.path.join(test_folder, filename))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Source folder path\n",
    "    src_folder = r'C:\\Users\\grizi\\Desktop\\TUD\\year2\\thesis\\neural_network\\DoA_Net\\data\\mic_dev\\mic_dev'\n",
    "    # Destination folders path\n",
    "    train_folder = r'C:\\Users\\grizi\\Desktop\\TUD\\year2\\thesis\\neural_network\\DoA_Net\\data\\ov1_mic_dev\\train'\n",
    "    val_folder = r'C:\\Users\\grizi\\Desktop\\TUD\\year2\\thesis\\neural_network\\DoA_Net\\data\\ov1_mic_dev\\val'\n",
    "    test_folder = r'C:\\Users\\grizi\\Desktop\\TUD\\year2\\thesis\\neural_network\\DoA_Net\\data\\ov1_mic_dev\\test'\n",
    "    \n",
    "    # Split files\n",
    "    split_ov1_files_into_folders(src_folder, train_folder, val_folder, test_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then split the label file to training, testing and valid set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def split_csv_files_into_folders(src_folder, train_folder, val_folder, test_folder):\n",
    "    # Create destination folders if they don't exist\n",
    "    for folder in [train_folder, val_folder, test_folder]:\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "    \n",
    "    # Iterate over all files in the source folder\n",
    "    for filename in os.listdir(src_folder):\n",
    "        # Check if the file ends with '.csv' and move to the corresponding folder\n",
    "        if filename.endswith('_ov1.csv'):\n",
    "            if filename.startswith(('fold3', 'fold4', 'fold5', 'fold6')):\n",
    "                shutil.move(os.path.join(src_folder, filename), os.path.join(train_folder, filename))\n",
    "            elif filename.startswith('fold2'):\n",
    "                shutil.move(os.path.join(src_folder, filename), os.path.join(val_folder, filename))\n",
    "            elif filename.startswith('fold1'):\n",
    "                shutil.move(os.path.join(src_folder, filename), os.path.join(test_folder, filename))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Source folder path\n",
    "    src_folder = r'C:\\Users\\grizi\\Desktop\\TUD\\year2\\thesis\\neural_network\\DoA_Net\\data\\metadata_dev\\metadata_dev'\n",
    "    # Destination folders path\n",
    "    train_folder = r'C:\\Users\\grizi\\Desktop\\TUD\\year2\\thesis\\neural_network\\DoA_Net\\data\\csv_dev\\train'\n",
    "    val_folder = r'C:\\Users\\grizi\\Desktop\\TUD\\year2\\thesis\\neural_network\\DoA_Net\\data\\csv_dev\\val'\n",
    "    test_folder = r'C:\\Users\\grizi\\Desktop\\TUD\\year2\\thesis\\neural_network\\DoA_Net\\data\\csv_dev\\test'\n",
    "    \n",
    "    # Split files\n",
    "    split_csv_files_into_folders(src_folder, train_folder, val_folder, test_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Align the sound data with the label data and save in a h5 file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98396, 2400, 4)\n",
      "(98396, 5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Specify the folder path where the CSV files are located\n",
    "folder_path = r\"C:\\Users\\grizi\\Desktop\\TUD\\year2\\thesis\\neural_network\\DoA_Net\\data\\csv_dev\\train\"\n",
    "# Specify the path where the .h5 file will be saved\n",
    "h5_file_path = r\"C:\\Users\\grizi\\Desktop\\TUD\\year2\\thesis\\neural_network\\DoA_Net\\data\\training_more.h5\"\n",
    "\n",
    "start = 1\n",
    "wav_data = []\n",
    "\n",
    "# Create an H5 file to store all the data\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith(\".csv\"):  # Ensure only .csv files are processed\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        # find the correlated wav file\n",
    "        wav_path = file_path.replace('csv_dev', 'ov1_mic_dev').replace('csv', 'wav').replace('csv', 'wav')\n",
    "\n",
    "        # get the audio data from the wav file\n",
    "        audio_data = read_wav_file(wav_path)\n",
    "\n",
    "        # Read the CSV file into a pandas DataFrame\n",
    "        df = pd.read_csv(file_path, header=None)\n",
    "        df_array = np.array(df)\n",
    "        if start == 1:\n",
    "            dir_data = df_array\n",
    "            start = 0   \n",
    "        else:\n",
    "            dir_data = np.vstack((dir_data, df_array))\n",
    "        \n",
    "        # get the related audio data with respect to the ground truth labels\n",
    "        for i in range(len(df_array)):\n",
    "            index = int(df_array[i][0])  # Assuming the first column contains the index\n",
    "            start_idx = int(index * 0.1 * 24000)  # Convert to integer index\n",
    "            end_idx = start_idx + 2400  # The end index for the slice\n",
    "            \n",
    "            # Append the audio data slice to the wav_data list\n",
    "            wav_data.append(audio_data[start_idx:end_idx, :])\n",
    "            if audio_data[start_idx:end_idx, :].shape != (2400, 4):\n",
    "                print(index,start_idx,end_idx)\n",
    "                print(audio_data[start_idx:end_idx, :].shape)\n",
    "\n",
    "wav_data = np.array(wav_data)\n",
    "print(wav_data.shape)\n",
    "print(dir_data.shape)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "# Save the label data to the h5 file\n",
    "with h5py.File(h5_file_path, 'w') as h5file:\n",
    "    h5file.create_dataset('label', data=dir_data)\n",
    "    h5file.create_dataset('audio', data=wav_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the test set to a h5 file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19151, 2400, 4)\n",
      "(19151, 5)\n"
     ]
    }
   ],
   "source": [
    "# Specify the folder path where the CSV files are located\n",
    "folder_path = r\"C:\\Users\\grizi\\Desktop\\TUD\\year2\\thesis\\neural_network\\DoA_Net\\data\\csv_dev\\test\"\n",
    "# Specify the path where the .h5 file will be saved\n",
    "h5_file_path = r\"C:\\Users\\grizi\\Desktop\\TUD\\year2\\thesis\\neural_network\\DoA_Net\\data\\test.h5\"\n",
    "\n",
    "start = 1\n",
    "wav_data = []\n",
    "\n",
    "# Create an H5 file to store all the data\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith(\".csv\"):  # Ensure only .csv files are processed\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        # find the correlated wav file\n",
    "        wav_path = file_path.replace('csv_dev', 'ov1_mic_dev').replace('csv', 'wav').replace('csv', 'wav')\n",
    "\n",
    "        # get the audio data from the wav file\n",
    "        audio_data = read_wav_file(wav_path)\n",
    "\n",
    "        # Read the CSV file into a pandas DataFrame\n",
    "        df = pd.read_csv(file_path, header=None)\n",
    "        df_array = np.array(df)\n",
    "        if start == 1:\n",
    "            dir_data = df_array\n",
    "            start = 0   \n",
    "        else:\n",
    "            dir_data = np.vstack((dir_data, df_array))\n",
    "        \n",
    "        # get the related audio data with respect to the ground truth labels\n",
    "        for i in range(len(df_array)):\n",
    "            index = int(df_array[i][0])  # Assuming the first column contains the index\n",
    "            start_idx = int(index * 0.1 * 24000)  # Convert to integer index\n",
    "            end_idx = start_idx + 2400  # The end index for the slice\n",
    "            \n",
    "            # Append the audio data slice to the wav_data list\n",
    "            wav_data.append(audio_data[start_idx:end_idx, :])\n",
    "            if audio_data[start_idx:end_idx, :].shape != (2400, 4):\n",
    "                print(index,start_idx,end_idx)\n",
    "                print(audio_data[start_idx:end_idx, :].shape)\n",
    "\n",
    "wav_data = np.array(wav_data)\n",
    "print(wav_data.shape)\n",
    "print(dir_data.shape)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "# Save the label data to the h5 file\n",
    "with h5py.File(h5_file_path, 'w') as h5file:\n",
    "    h5file.create_dataset('label', data=dir_data)\n",
    "    h5file.create_dataset('audio', data=wav_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the content of the train and test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: audio, Shape: (98396, 2400, 4)\n",
      "Dataset: label, Shape: (98396, 5)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "# Path to the H5 file\n",
    "h5_file_path = r\"C:\\Users\\grizi\\Desktop\\TUD\\year2\\thesis\\neural_network\\DoA_Net\\data\\training_more.h5\"\n",
    "\n",
    "# Open the H5 file\n",
    "with h5py.File(h5_file_path, 'r') as h5file:\n",
    "    # Iterate through each dataset in the H5 file\n",
    "    for dataset_name in h5file:\n",
    "        # Get the dataset\n",
    "        dataset = h5file[dataset_name]\n",
    "        if dataset_name == 'audio':\n",
    "            audio_data = np.array(dataset)\n",
    "        else:\n",
    "            label_data = np.array(dataset)\n",
    "        \n",
    "        # Print the dataset name and its shape\n",
    "        print(f\"Dataset: {dataset_name}, Shape: {dataset.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: audio, Shape: (19151, 2400, 4)\n",
      "Dataset: label, Shape: (19151, 5)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "# Path to the H5 file\n",
    "h5_file_path = r\"C:\\Users\\grizi\\Desktop\\TUD\\year2\\thesis\\neural_network\\DoA_Net\\data\\test.h5\"\n",
    "\n",
    "# Open the H5 file\n",
    "with h5py.File(h5_file_path, 'r') as h5file:\n",
    "    # Iterate through each dataset in the H5 file\n",
    "    for dataset_name in h5file:\n",
    "        # Get the dataset\n",
    "        dataset = h5file[dataset_name]\n",
    "        if dataset_name == 'audio':\n",
    "            audio_data = np.array(dataset)\n",
    "        else:\n",
    "            label_data = np.array(dataset)\n",
    "        \n",
    "        # Print the dataset name and its shape\n",
    "        print(f\"Dataset: {dataset_name}, Shape: {dataset.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Extract the GCC-PHAT from the audio message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to calculate GCC-PHAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import fftconvolve\n",
    "\n",
    "def gcc_phat(signal_i, signal_j, fs, max_tau=None, interp=1):\n",
    "    \"\"\"\n",
    "    Compute the GCC-PHAT between two signals.\n",
    "    Parameters:\n",
    "        signal_i: np.ndarray\n",
    "            Signal from microphone i.\n",
    "        signal_j: np.ndarray\n",
    "            Signal from microphone j.\n",
    "        fs: int\n",
    "            Sampling frequency of the signals.\n",
    "        max_tau: float, optional\n",
    "            Maximum delay (in seconds) to consider.\n",
    "        interp: int, optional\n",
    "            Interpolation factor for GCC-PHAT.\n",
    "    Returns:\n",
    "        gcc: np.ndarray\n",
    "            GCC-PHAT values.\n",
    "        tau: np.ndarray\n",
    "            Time delays corresponding to the GCC-PHAT values.\n",
    "    \"\"\"\n",
    "    n = signal_i.shape[0] + signal_j.shape[0] - 1\n",
    "    n_fft = 2 ** int(np.ceil(np.log2(n)))\n",
    "\n",
    "    # Compute FFT of both signals\n",
    "    X_i = np.fft.rfft(signal_i, n=n_fft)\n",
    "    X_j = np.fft.rfft(signal_j, n=n_fft)\n",
    "\n",
    "    # Compute cross-power spectrum\n",
    "    cross_power = X_i * np.conj(X_j)\n",
    "    epsilon = 1e-10  \n",
    "    cross_power /= (np.abs(cross_power) + epsilon)\n",
    "\n",
    "    # Compute inverse FFT to get GCC\n",
    "    gcc = np.fft.irfft(cross_power, n=n_fft)\n",
    "    \n",
    "    # Shift to center the peak\n",
    "    max_shift = int(n_fft / 2)\n",
    "    gcc = np.roll(gcc, max_shift)\n",
    "\n",
    "    # Compute time delays\n",
    "    tau = np.linspace(-max_shift / fs, max_shift / fs, num=n_fft)\n",
    "\n",
    "    # Limit to max_tau if specified\n",
    "    if max_tau:\n",
    "        max_shift = int(fs * max_tau)\n",
    "        gcc = gcc[n_fft // 2 - max_shift : n_fft // 2 + max_shift]\n",
    "        tau = tau[n_fft // 2 - max_shift : n_fft // 2 + max_shift]\n",
    "\n",
    "    return gcc, tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19151, 2400, 4)\n",
      "(19151, 51, 6)\n"
     ]
    }
   ],
   "source": [
    "print(wav_data.shape)\n",
    "gcc_vectors_all = []\n",
    "for k in range(audio_data.shape[0]):\n",
    "    test_audio_data = audio_data[k,:,:]\n",
    "    fs = 24000 \n",
    "    gcc_vectors = []\n",
    "    for i in range(4):\n",
    "        for j in range(i+1,4):\n",
    "            signal_i = test_audio_data[:,i] # get the data from the first microphone\n",
    "            signal_j = test_audio_data[:,j] # get the data from the second microphone\n",
    "\n",
    "            # # calculate GCC-PHAT\n",
    "            gcc, tau = gcc_phat(signal_i, signal_j, fs)\n",
    "            selected_gcc = gcc[len(gcc)//2 - 25 : len(gcc)//2 + 26]\n",
    "            gcc_vectors.append(selected_gcc)\n",
    "\n",
    "    gcc_vectors = np.array(gcc_vectors).T\n",
    "    gcc_vectors_all.append(gcc_vectors)\n",
    "\n",
    "gcc_vectors_all = np.array(gcc_vectors_all)\n",
    "print(gcc_vectors_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have already prepared all the data we need to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the H5 file\n",
    "with h5py.File(h5_file_path, 'a') as h5file:\n",
    "    h5file.create_dataset('gcc_vectors', data=gcc_vectors_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: audio, Shape: (19151, 2400, 4)\n",
      "Dataset: gcc_vectors, Shape: (19151, 51, 6)\n",
      "Dataset: label, Shape: (19151, 5)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(h5_file_path, 'r') as h5file:\n",
    "    # Iterate through each dataset in the H5 file\n",
    "    for dataset_name in h5file:\n",
    "        # Get the dataset\n",
    "        dataset = h5file[dataset_name]\n",
    "        \n",
    "        # Print the dataset name and its shape\n",
    "        print(f\"Dataset: {dataset_name}, Shape: {dataset.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seld",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
